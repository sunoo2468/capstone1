from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from datetime import datetime
import time

def scrape_cnn_articles_daily(max_articles=100):
    """
    CNN ë©”ì¸ í˜ì´ì§€ì—ì„œ ë‚ ì§œ ê¸°ë°˜ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ìµœëŒ€ max_articlesê°œ ìˆ˜ì§‘
    """
    base_url = "https://edition.cnn.com"
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920x1080")

    driver = webdriver.Chrome(options=options)
    driver.get(base_url)
    time.sleep(5)

    # ë‚ ì§œ íŒ¨í„´ í¬í•¨ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ë§Œ ì¶”ì¶œ
    links = driver.find_elements(By.CSS_SELECTOR, "a[href*='/2024/'], a[href*='/2025/']")
    article_links = list(set([
        link.get_attribute("href")
        for link in links
        if link.get_attribute("href") and "cnn.com" in link.get_attribute("href") and "html" in link.get_attribute("href")
    ]))

    print(f"ğŸ”— ìœ íš¨í•œ ë§í¬ ìˆ˜: {len(article_links)}")

    articles = []

    for link in article_links:
        try:
            driver.get(link)
            time.sleep(1.5)

            title = driver.title
            paragraphs = driver.find_elements(By.TAG_NAME, "p")
            content = "\n".join([p.text for p in paragraphs if p.text.strip()])

            if len(content) > 500:  # ë³¸ë¬¸ ê¸¸ì´ í•„í„°
                articles.append({
                    "url": link,
                    "title": title,
                    "content": content,
                    "date": datetime.today().strftime("%Y-%m-%d")
                })

            if len(articles) >= max_articles:
                break

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ë§í¬: {link} â€” {e}")
            continue

    driver.quit()
    print(f"âœ… ìµœì¢… ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}")
    return articles
